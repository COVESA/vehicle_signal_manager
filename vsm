#!/usr/bin/env python3
#
# Copyright (C) 2017, Jaguar Land Rover
#
# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at http://mozilla.org/MPL/2.0/.
#
# Authors:
#  * Gustavo Noronha <gustavo.noronha@collabora.com>
#  * Shane Fagan <shane.fagan@collabora.com>

import sys
import os
import argparse
import yaml
import ast
import threading
import time
import json
from ipc.loader import load_plugin, LoaderError


LOGIC_REPLACE = {'||': 'or',
                 '&&': 'and',
                 'true': 'True',
                 'false': 'False'}

LOG_FILE_PATH_DEFAULT = 'vsm.log'

LOG_CAT_CONDITION_CHECKS = 'condition-checks'

SIGNAL_PREFIX_OUTGOING = '<'
SIGNAL_PREFIX_INCOMING = '>'
SIGNAL_PREFIX_DELIM = ' '

REPLAY_RATE_MIN = 1
REPLAY_RATE_MAX = 10000

NODE_CONDITION = 'condition'
NODE_EMIT = 'emit'

start_time_ms = 0
logger = None


def _format_signal_msg(signal, value, indicator):
    # NOTE: the "[SIGNUM]" field is a temporary placeholder for the signal ID
    return '{} {},{},[SIGNUM],{}'.format(indicator, get_runtime(),
                                         signal, repr(value))

def _handle_xor_condition(condition):
    '''
        Group within parentheses sub-clauses of XOR expressions and replace
        its operator (^^) by the not equality operator (!=)
    '''
    try:
        lhs, rhs = condition.split('^^')
    except ValueError:
        return condition

    return "({}) != ({})".format(lhs.strip(), rhs.strip())


class Logger(object):
    '''
        Utility class for logging messages
    '''

    def __init__(self, pipeout_fd):
        self.pipeout_fd = pipeout_fd

    def i(self, msg, timestamp=True):
        '''
            Log an informative (non-error) message
        '''
        os.write(self.pipeout_fd, (msg + '\n').encode('UTF-8'))

    def e(self, msg, timestamp=True):
        '''
            Log an error
        '''
        os.write(self.pipeout_fd, (msg + '\n').encode('UTF-8'))

    def signal(self, signal, value, indicator):
        '''
            Log signal emission/reception
        '''
        msg = _format_signal_msg(signal, value, indicator)
        os.write(self.pipeout_fd, (msg + '\n').encode('UTF-8'))

class Catapult(Logger):

    def __init__(self, pipeout_fd):
        super().__init__(pipeout_fd)
        self.pid = os.getpid()

        # Open the JSON Array file
        os.write(self.pipeout_fd, '[\n'.encode('UTF-8'))

    def i(self, msg, timestamp=True):
        pass

    def e(self, msg, timestamp=True):
        pass

    def signal(self, signal, value, indicator):
        '''
            Log signal emission/reception using the catapult format
        '''
        # A JSON object represents a catapult trace event
        sigtype = 'incoming' if indicator == SIGNAL_PREFIX_INCOMING else 'outgoing'
        event = {
            "name": signal,
            "pid": self.pid,
            "ts": (get_runtime() * 1000),
            "cat": "signal,{}".format(sigtype),
            "ph": "i",
            "args": { "value": value }
        }
        os.write(self.pipeout_fd, (json.dumps(event) + ',\n').encode('UTF-8'))

class State(object):
    '''
        Class to handle states
    '''
    def __init__(self, initial_state, rules, log_categories):
        class VariablesStorage(object):
            pass
        self.variables = VariablesStorage()
        self.log_categories = log_categories

        self.rules = {}
        with open(rules) as rules_file:
            self.parse_rules(rules_file)

        if initial_state:
            with open(initial_state) as f:
                data = yaml.load(f.read())

                for item in data:
                    item = item.replace(" ", "").split("=")
                    vars(self.variables)[item[0]] = item[1]


    def handle_emit(self, data, condition):
        signal = data[NODE_EMIT]["signal"]
        value = data[NODE_EMIT]["value"]

        if "delay" in data[NODE_EMIT].keys():
            action = "threading.Thread(target=delayed_emit, args=( \
                            \'{}\', \'{}\', {})).start()".format(signal,
                            value, data[NODE_EMIT]["delay"])
        else:
            action = "emit(\'{}\', \'{}\')".format(signal, value)

        action = ast.parse(action)

        if condition == True:
            return action.body[0]
        else:
            rule = compile(action, '<string>', 'exec')
            exec(rule)

    def handle_condition(self, data):
        orig_condition = data[NODE_CONDITION]
        # Handle XOR operator (if it is found)
        if orig_condition.find('^^') >= 0:
            condition = _handle_xor_condition(orig_condition)
        else:
            condition = orig_condition

        condition_expr = ast.parse(condition).body[0]

        # Parse identifiers (variables).
        parser = ParseIdentifiers()
        parser.visit(condition_expr)

        # Replace dot (.) by underscore (_) in the condition identifiers so they
        # can be correctly interpreted like Python variables.
        eval_condition = self._undot_identifiers(condition, parser.identifiers)
        eval_condition_expr = ast.parse(eval_condition).body[0]

        action_true_1_body = self.handle_emit(data, True)
        actions_true = [action_true_1_body]
        actions_false = []

        if self.log_categories[LOG_CAT_CONDITION_CHECKS]:
            action_true_2_code = self.generate_condition_code(orig_condition, True)
            action_true_2 = ast.parse(action_true_2_code)

            action_false_code = self.generate_condition_code(orig_condition, False)
            action_false = ast.parse(action_false_code)

            actions_true.append(action_true_2.body[0])
            actions_false.append(action_false.body[0])

        ifnode = ast.If(eval_condition_expr.value, actions_true, actions_false)
        ast_module = ast.Module([ifnode])

        ast.fix_missing_locations(ast_module)

        rule = compile(ast_module, '<string>', 'exec')
        self.add_rule(parser.identifiers, rule)

    def generate_condition_code(self, condition, result):
        return "logger.i(\"condition: ({}) => {}\")".format(condition,
                str(result))

    def __parse_items(self, item):
        keys = list(item.keys())
        if NODE_CONDITION in item:
            self.handle_condition(item)
        elif NODE_EMIT in item:
            self.handle_emit(item, False)

    def parse_rules(self, rules_file):
        '''
            Parse YAML rules for policy manager and return ast code.
        '''
        data = rules_file.read()

        # Translate logical operations to Python, so that they
        # can be compiled.
        for key, value in LOGIC_REPLACE.items():
             data = data.replace(key, value).strip()

        data = yaml.safe_load(data)
        # Currently we support only lists in yaml at base level
        if issubclass(type(data), list):
            for item in data:
                self.__parse_items(item)

    def add_rule(self, identifiers, rule):
        for signal_name in identifiers:
            if not signal_name in self.rules:
                self.rules[signal_name] = []
            self.rules[signal_name].append(rule)

    def got_signal(self, signal, value):
        self.got_signal_record(signal, value)

        # No conditions based on the signal that was emitted,
        # nothing to be done.
        if not signal in self.rules:
            return

        for rule in self.rules[signal]:
            try:
                exec(rule, globals(), self._undot_variables(vars(self.variables)))
            except NameError:
                # Names used in rules are not always present
                # in the state.
                pass

    def got_signal_record(self, signal, value):
        vars(self.variables)[signal] = value

        # Record received signal in logs.
        logger.signal(signal, value, SIGNAL_PREFIX_INCOMING)

        logger.i("State = {")
        for k, v in sorted(vars(self.variables).items()):
            logger.i("{} = {}".format(k, v))
        logger.i("}")

    def _undot_identifiers(self, condition, identifiers):
        for ident in identifiers:
            # Replace '.' by '_' in identifiers.
            if ident.find('.') >= 0:
                condition = condition.replace(ident, ident.replace('.', '_'))
        return condition

    def _undot_variables(self, variables):
        # Replace '.' by '_' in variables names (identifiers)
        return { k.replace('.', '_'): v for k, v in variables.items() }

class ParseIdentifiers(ast.NodeVisitor):
    '''
        Class to parse identifiers (signals and attributes names)
    '''

    def __init__(self):
        self.identifiers = []
        self._attributes = []

    def visit_Name(self, node):
        def make_identifier(node_id):
            return '.'.join(reversed(self._attributes + [node.id]))

        if self._attributes:
            # If a name is found with attributes available, build the identifier
            # and reset the attributes list.
            self.identifiers.append(make_identifier(node.id))
            self._attributes = []
        else:
            self.identifiers.append(node.id)

        super().generic_visit(node)

    def visit_Attribute(self, node):
        self._attributes.append(node.attr)
        super().generic_visit(node)

class LogReplayer(object):
    '''
        Class to enact log file replaying (signals only)
    '''

    signals = []

    def __init__(self, state, replay_log, replay_rate):
        with open(replay_log) as f:
            content = f.readlines()
            for line in content:
                self.__parse_replay_log_line(line)

        for signal in self.signals:
            # by default, don't adjust time scale (ie, 100%)
            scaled_delay_ms = signal.time_ms
            if replay_rate:
                scaled_delay_ms = signal.time_ms / (replay_rate / 100)

            remaining_delay_ms = max(scaled_delay_ms - get_runtime(), 0)

            if signal.direction == self.Signal.DIRECTION_IN:
                delayed_got_signal(signal.name, signal.value,
                        remaining_delay_ms, state)
            if signal.direction == self.Signal.DIRECTION_OUT:
                delayed_emit(signal.name, signal.value, remaining_delay_ms,
                        state)

    def __parse_replay_log_line(self, line):
        if SIGNAL_PREFIX_DELIM not in line:
            return

        prefix, remainder = line.split(SIGNAL_PREFIX_DELIM, 1)
        direction = None
        if prefix == SIGNAL_PREFIX_INCOMING:
            direction = self.Signal.DIRECTION_IN

        if prefix == SIGNAL_PREFIX_OUTGOING:
            direction = self.Signal.DIRECTION_OUT

        if direction:
            try:
                time_ms, name, signum, value = remainder.split(',')
                time_ms = int(time_ms)
                # eval() the value to effectively reverse the excessive repr()
                # which will be applied before printing this value (which would
                # result in values like "'True'\n" instead of 'True'
                value = eval(value)
                self.signals.append(self.Signal(direction, time_ms, name,
                    value))
            except ValueError as err:
                logger.e('failed to parse line (invalid number of elements): ' +
                        '{}; line was:\n{}'.format(err, line))

                return

    class Signal:
        DIRECTION_OUT = 'out'
        DIRECTION_IN = 'in'

        def __init__(self, direction, time_ms, name, value):
            self.direction = direction
            self.time_ms = time_ms
            self.name = name
            self.value = value

def show(signal, value, indicator):
    '''
        Show signal emission/reception
    '''
    print(_format_signal_msg(signal, value, indicator))

def send(signal, value):
    show(signal, value, SIGNAL_PREFIX_OUTGOING)

# this includes an unused state parameter so it matches the signature of
# delayed_got_signal() for log replay purposes
def delayed_emit(signal, value, delay, state=None):
    time.sleep(delay/1000)
    emit(signal, value)

def emit(signal, value):
    # Record sent signal in logs.
    logger.signal(signal, value, SIGNAL_PREFIX_OUTGOING)
    send(signal, value)

def delayed_got_signal(signal, value, delay, state):
    time.sleep(delay/1000)
    show(signal, value, SIGNAL_PREFIX_INCOMING)
    state.got_signal_record(signal, value)

def process(state, signal, value):
    '''
        Handle the emitting of signals and adding values to state
    '''
    def is_string(value):
        if not isinstance(value, str) or len(value) <= 2:
            return False
        return (value[0] == '"' and value[-1] == '"') or \
            (value[0] == "'" and value[-1] == "'")

    def is_bool(value):
        return value == 'true' or value == 'false'

    # Check and convert value to the types: string, bool, float or int
    try:
        if value == None:
            raise ValueError
        if is_string(value):
            value = value[1:-1]
        elif is_bool(value):
            value = value == 'true' or False
        elif value.find('.') >= 0:
            value = float(value)
        elif value.isnumeric():
            value = int(value)
        else:
            raise ValueError
    except ValueError:
        logger.e('incorrect value: {}'.format(value))
        return

    state.got_signal(signal, value)

def log_processor(pipein_fd, log_file_path):
    pipein = os.fdopen(pipein_fd)
    log_file = sys.stdout

    if log_file_path == None or log_file_path == '':
        log_file_path = LOG_FILE_PATH_DEFAULT

    if log_file_path != '-':
        try:
            log_file = open(log_file_path, 'w')
        except Exception as e:
            log_file.write("failed to open log file '{}': {}\n".format(
                log_file_path, e))

    for line in pipein:
        log_file.write(line)
        log_file.flush()

    if log_file_path:
        log_file.close()

    pipein.close()

def receive():
    '''
        Loop to grab logic from stdin
    '''
    for line in sys.stdin:
        line = line.replace(" ", "").strip('\n')
        if line == "":
            # Ignore blank lines
            continue
        if line == "quit":
            exit(0)
        elif "=" in line:
            line = line.split("=")
            show(line[0], line[1], SIGNAL_PREFIX_INCOMING)
            return (line[0], line[1])
        else:
            show(line, None, SIGNAL_PREFIX_INCOMING)
            return (line, None)

def run(state):
    try:
        while True:
            message = receive()
            if message == None:
                exit(0)

            signal, value = message
            # 'quit' signal to close VSM endpoint.
            if signal == 'quit':
                send('', '')
                break

            process(state, signal, value)
    except KeyboardInterrupt:
        exit(0)

def get_runtime():
    return round(time.perf_counter() * 1000 - start_time_ms)

if __name__ == "__main__":
    start_time_ms = round(time.perf_counter() * 1000)

    parser = argparse.ArgumentParser()
    parser.add_argument('--initial-state', type=str,
                        help='Initial state, yaml file', required=False)
    parser.add_argument('rules', type=str,
                        help='yaml rules configuration')
    parser.add_argument('--ipc-module', type=str, help='Load IPC module')
    parser.add_argument('--log-file', type=str,
            help='Write extra (non-signal emission) output to this file')
    parser.add_argument('--no-log-condition-checks',
            dest='log_condition_checks', action='store_false',
            help='Do not log condition checks (default: log them)')
    parser.add_argument('--replay-log-file', type=str,
            help='Use a log file to replay signal emission in real or scaled ' +
            'time')
    parser.add_argument('--replay-rate', type=float,
            help='The rate at which to play back the replay log. This value ' +
            'is a percentage of originally-recorded timing, specified as a ' +
            'decimal between ' + str(REPLAY_RATE_MIN) + ' and ' +
            str(REPLAY_RATE_MAX) + '. A value of 20 signifies playback at ' +
            '20%% of the original rate (ie, it will take 5 times as long to ' +
            'complete playback vs 100%%)')
    parser.set_defaults(log_condition_checks=True)
    parser.add_argument('--log-format', choices=['catapult'],
                        help='Write log file in specified format')
    args = parser.parse_args()

    log_categories = {LOG_CAT_CONDITION_CHECKS: args.log_condition_checks}

    if args.replay_rate and \
            (args.replay_rate < REPLAY_RATE_MIN or \
                    args.replay_rate > REPLAY_RATE_MAX):
        print('Replay rate must be between {} and {}, inclusive'.format(
            REPLAY_RATE_MIN, REPLAY_RATE_MAX), file=sys.stderr)
        exit(1)

    # fork separate process to handle logging so we don't block main process
    pipein_fd, pipeout_fd = os.pipe()
    if os.fork() == 0:
        os.close(pipeout_fd)
        log_processor(pipein_fd, args.log_file)
    else:
        os.close(pipein_fd)

        if args.log_format == 'catapult':
            logger = Catapult(pipeout_fd)
        else:
            logger = Logger(pipeout_fd)

        if args.ipc_module:
            # Load IPC plugin.
            # Override the receive/send functions with the plugin version.
            try:
                load_plugin('ipc.{}'.format(args.ipc_module))
            except LoaderError as err:
                logger.e(err)
                exit(1)

        state = State(args.initial_state, args.rules, log_categories)

        if args.replay_log_file:
            LogReplayer(state, args.replay_log_file, args.replay_rate)

        run(state)
